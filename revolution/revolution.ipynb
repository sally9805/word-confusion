{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e5BxU6ySSSa"
      },
      "source": [
        "## Set up\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtF9YJOYY2ri"
      },
      "outputs": [],
      "source": [
        "# @title Params {display-mode: \"form\"}\n",
        "dest_dir = 'embeddings/' # @param   {type: \"string\", isTemplate: true}\n",
        "data_dir = 'AP XML/' # @param   {type: \"string\", isTemplate: true}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jT9FynSEz_k7"
      },
      "outputs": [],
      "source": [
        "!mkdir -p $dest_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCCEXcLMv2ep"
      },
      "outputs": [],
      "source": [
        "# @title Import {display-mode: \"form\"}\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import tqdm\n",
        "from transformers import pipeline\n",
        "from transformers import BertConfig\n",
        "from transformers import BertModel\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os.path\n",
        "from os import path\n",
        "\n",
        "from transformers import *\n",
        "from collections import Counter\n",
        "\n",
        "import math\n",
        "import csv\n",
        "import tqdm\n",
        "import re\n",
        "import os\n",
        "import re\n",
        "\n",
        "import xml.etree.ElementTree as ET\n",
        "import xml.dom.minidom as minidom"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhb3dlX2w8v1"
      },
      "source": [
        "## Find word occurrences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Huo0Ttt5Sz07"
      },
      "outputs": [],
      "source": [
        "def write_to_file(result, result_file):\n",
        "    result.to_csv(result_file, mode='w', index=False)\n",
        "    return pd.DataFrame()\n",
        "\n",
        "def extract_global_dates(tree):\n",
        "    root = tree.getroot() if tree.getroot() else tree\n",
        "    date_elements = root.findall('.//titlePart/date')\n",
        "    dates = [date.attrib['value'] for date in date_elements if 'value' in date.attrib]\n",
        "    return dates\n",
        "\n",
        "def write_data(keywords, elem, result, current_speaker, filename, date, year_sentence_count, year_limit=1500):\n",
        "    data = elem.text\n",
        "    if data:\n",
        "        data = data.replace(\"\\n\", \" \").strip()\n",
        "        data = re.sub('\\s{2,}', ' ', data)\n",
        "        for sentence in re.split('(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', data):\n",
        "            if len(sentence) > 512:\n",
        "                continue\n",
        "            for keyword in keywords:\n",
        "                if keyword in sentence and re.search(r\"\\b\" + keyword + r\"\\b\", sentence):\n",
        "                    year = date.split('-')[0] if date else None\n",
        "                    if year_sentence_count[year] >= year_limit:\n",
        "                        continue\n",
        "                    result = result._append({\n",
        "                        'keyword': keyword, 'sentence': sentence + \".\",\n",
        "                        'filename': filename, 'speaker': current_speaker,\n",
        "                        'date': date, 'year': year\n",
        "                    }, ignore_index=True)\n",
        "                    year_sentence_count[year] += 1\n",
        "    return result\n",
        "\n",
        "def find_keywords(keywords, result_file, data_dir, limit = 5000):\n",
        "    result = pd.DataFrame(columns=['keyword', 'sentence', 'filename', 'speaker', 'date'])\n",
        "    year_sentence_count = {}\n",
        "    for filename in os.listdir(data_dir):\n",
        "        if filename == 'APvol71_table.xml':\n",
        "            continue\n",
        "        file_path = os.path.join(data_dir, filename)\n",
        "        tree = ET.parse(file_path)\n",
        "        dates = extract_global_dates(tree)\n",
        "        current_speaker = \"None\"\n",
        "        for elem in tree.iter():\n",
        "            if elem.tag == 'p' or elem.tag == 'sp':\n",
        "                for date in dates:\n",
        "                    year = date.split('-')[0] if date else None\n",
        "                    if year not in year_sentence_count:\n",
        "                        year_sentence_count[year] = 0\n",
        "                    result = write_data(keywords, elem, result, current_speaker, filename, date, year_sentence_count)\n",
        "            if elem.tag == 'speaker':\n",
        "                current_speaker = elem.text.strip() if elem.text else \"None\"\n",
        "\n",
        "        if len(result) > limit:\n",
        "            result = write_to_file(result, result_file)\n",
        "            return result\n",
        "\n",
        "    if len(result) > 0:\n",
        "        write_to_file(result, result_file)\n",
        "\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2uYQvMfw5nh"
      },
      "outputs": [],
      "source": [
        "keywords = ['Révolution', 'Révolutions', 'révolution', 'contre-révolution', 'contre-révolutions']\n",
        "for k in keywords:\n",
        "  keyword = [k]\n",
        "  file_name = dest_dir + k + '_words_with_speaker.csv'\n",
        "  result = find_keywords(keyword, file_name, data_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "715GXH42R54H"
      },
      "source": [
        "## [Optional] Print Dataset Stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLe1IOuRd3BW"
      },
      "source": [
        "### Entire data stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Cp10Kuxccp6"
      },
      "outputs": [],
      "source": [
        "def process_documents(directory):\n",
        "    stats = {}\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith('.xml'):  # Process only XML files\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            tree = ET.parse(file_path)\n",
        "            dates = extract_global_dates(tree)  # Extract global dates from the document metadata\n",
        "            current_speaker = \"None\"\n",
        "            for elem in tree.iter():\n",
        "                if elem.tag in ['p', 'sp']:\n",
        "                    for date in dates:\n",
        "                        year = date.split('-')[0] if date else None\n",
        "                        if year not in stats:\n",
        "                            stats[year] = {'total_words': 0, 'unique_speakers': set()}\n",
        "                        if elem.text:\n",
        "                            sentence = re.sub('[\\n\\s]+', ' ', elem.text.strip())\n",
        "                            words = sentence.split()\n",
        "                            stats[year]['total_words'] += len(words)\n",
        "                            stats[year]['unique_speakers'].add(current_speaker)\n",
        "                if elem.tag == 'speaker' and elem.text:\n",
        "                    current_speaker = elem.text.strip()\n",
        "\n",
        "    # Convert unique_speakers sets to counts\n",
        "    for year in stats:\n",
        "        stats[year]['unique_speakers'] = len(stats[year]['unique_speakers'])\n",
        "\n",
        "    return stats\n",
        "\n",
        "def extract_global_dates(tree):\n",
        "    date_elements = tree.findall('.//titlePart/date')\n",
        "    return [date.attrib['value'] for date in date_elements if 'value' in date.attrib]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpquPTOhedWg",
        "outputId": "51b69a28-8105-4f73-f292-91acc3f9a908"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Year: 1789\n",
            "Total Words: 5081835\n",
            "Unique Speakers: 1757\n",
            "\n",
            "Year: 1790\n",
            "Total Words: 10640605\n",
            "Unique Speakers: 2236\n",
            "\n",
            "Year: 1791\n",
            "Total Words: 16225976\n",
            "Unique Speakers: 2668\n",
            "\n",
            "Year: 1792\n",
            "Total Words: 10633752\n",
            "Unique Speakers: 1681\n",
            "\n",
            "Year: 1793\n",
            "Total Words: 11877982\n",
            "Unique Speakers: 1286\n",
            "\n",
            "Total Words: 54460150\n",
            "Unique Speakers: 9628\n"
          ]
        }
      ],
      "source": [
        "stats = process_documents(data_dir)\n",
        "total_words = 0\n",
        "unique_speakers = 0\n",
        "for year, data in stats.items():\n",
        "  total_words += data['total_words']\n",
        "  unique_speakers += data['unique_speakers']\n",
        "  print(f\"Year: {year}\")\n",
        "  print(f\"Total Words: {data['total_words']}\")\n",
        "  print(f\"Unique Speakers: {data['unique_speakers']}\")\n",
        "  print()\n",
        "\n",
        "print(f\"Total Words: {total_words}\")\n",
        "print(f\"Unique Speakers: {unique_speakers}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4k1HXctJR-Z2"
      },
      "source": [
        "### Single Keyword Stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjLBz8XTSBMH"
      },
      "outputs": [],
      "source": [
        "def count_total_words_and_speeches(df):\n",
        "    df['word_count'] = df['sentence'].apply(lambda x: len(x.split()))\n",
        "\n",
        "    total_words = df['word_count'].sum()\n",
        "    unique_speeches = len(df['speaker'].unique())\n",
        "\n",
        "    summary = {\n",
        "        'total_words': total_words,\n",
        "        'unique_speeches': unique_speeches\n",
        "    }\n",
        "\n",
        "    return summary\n",
        "\n",
        "word = 'Révolution'\n",
        "file_name = dest_dir + word + '_words_with_speaker.csv'\n",
        "data = pd.read_csv(file_name)\n",
        "count_total_words_and_speeches(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRFGCaUh0mQd"
      },
      "source": [
        "### Visualize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHJTPcEr0lbX"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_colwidth', 0)\n",
        "data = pd.read_csv(file_name)\n",
        "data['sentence'] = data['sentence'].apply(lambda x: x.strip().replace(\"\\n\", \" \"))\n",
        "data['sentence'] = data['sentence'].apply(lambda x: re.sub(' +', ' ', x))\n",
        "data = data.drop_duplicates(subset='sentence')\n",
        "data.to_csv(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnje-jjk0tdJ"
      },
      "outputs": [],
      "source": [
        "data.groupby('date').count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "vzyrAHSg0wJR",
        "outputId": "a436d777-b2d9-4c7b-fa41-44e449254e69"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 1100,\n  \"fields\": [\n    {\n      \"column\": \"keyword\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"R\\u00e9volution\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1100,\n        \"samples\": [\n          \"Tant que nous aurons d\\u00e9s contre-r\\u00e9tolutionnaires de ce c\\u00f4t\\u00e9, la R\\u00e9volution ne pourra pas marcher..\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"APvol80.xml\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"speaker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 217,\n        \"samples\": [\n          \"Sergent.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"1793-11-24\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1789,\n        \"max\": 1793,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1789\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-53524e8c-d685-49ff-9e94-8cd0baa6a78c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>keyword</th>\n",
              "      <th>sentence</th>\n",
              "      <th>filename</th>\n",
              "      <th>speaker</th>\n",
              "      <th>date</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Révolution</td>\n",
              "      <td>Lorsque nous n'avons pas le texte exact d'un discours dont l'auteur a joué un rôle important sous la Révolution, nous établissons le texte en coordonnant les journaux de l'époque, et pour permettre au lecteur de comparer les différences qui existent entre chacun d'eux, nous donnons en Annexe la version de ces divers journaux..</td>\n",
              "      <td>APvol62.xml</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1793-04-13</td>\n",
              "      <td>1793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Révolution</td>\n",
              "      <td>Comment, Marat aprè|s avoir peinti une partie de la Convention comme suspecte et ennemie de la Révolution, s'écrie : exterminons, sans pitié, tous les conspirateurs ; et l'on dira encore qu'il n'appelle pas le fer sur la tête d'une partie d'entre vous, sur les votants pour l'appel au peuple ou pour la, détention du tyran ou le sursis de son jugement !.</td>\n",
              "      <td>APvol62.xml</td>\n",
              "      <td>Delaunay</td>\n",
              "      <td>1793-04-13</td>\n",
              "      <td>1793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Révolution</td>\n",
              "      <td>Examinez ensuite la conduite de ce citoyen, depuis la Révolution..</td>\n",
              "      <td>APvol62.xml</td>\n",
              "      <td>Delaunay</td>\n",
              "      <td>1793-04-13</td>\n",
              "      <td>1793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Révolution</td>\n",
              "      <td>Attendu enfin que sans m'arrêter au style de Marat, ni à ses idées, je suis forcé de reconnaître en lui un des plus fermes appuis de la Révolution ; que ce citoyen a constamment dénoncé les traîtres et les plus grands conspirateurs, malgré les persécutions les plus fortes, je déclare en mon âme et conscience qu'il n'y a pas lieu à accusation..</td>\n",
              "      <td>APvol62.xml</td>\n",
              "      <td>Bentabole</td>\n",
              "      <td>1793-04-13</td>\n",
              "      <td>1793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Révolution</td>\n",
              "      <td>Provoquons mutuellement la censure publique sur nos actions ; que chacun soit tenu de justifier de ce qu'il a fait pour le peuple avant et depuis la Révolution ; qu'il en soit fait uni tableau soumis à la contradiction des citoyens: alors le peuple distinguera ses vrais amis ; il ne sera plus dupe de ceux qui ne le flattent tant aujourd'hui, que pour mieux l'asservir: je me réserve d'en faire la motion expresse..</td>\n",
              "      <td>APvol62.xml</td>\n",
              "      <td>Bernier</td>\n",
              "      <td>1793-04-13</td>\n",
              "      <td>1793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2196</th>\n",
              "      <td>Révolution</td>\n",
              "      <td>Vous penserez, Messieurs, que pour l'honneur de la nation française, pour le succès de cette Révolution, l'Assemblée doit prendre des précautions, pour mettre en sûreté les députés du clergé dont vous avez déclaré la personne inviolable et sacrée..</td>\n",
              "      <td>APvol9.xml</td>\n",
              "      <td>M. l'abbé Grégoire.</td>\n",
              "      <td>1789-09-16</td>\n",
              "      <td>1789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2198</th>\n",
              "      <td>Révolution</td>\n",
              "      <td>La Révolution qui a été commencée par le courage doit être achevée par la sagesse..</td>\n",
              "      <td>APvol9.xml</td>\n",
              "      <td>M. Bailly.</td>\n",
              "      <td>1789-09-16</td>\n",
              "      <td>1789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2200</th>\n",
              "      <td>Révolution</td>\n",
              "      <td>sur les suites de cette Révolution..</td>\n",
              "      <td>APvol9.xml</td>\n",
              "      <td>M. le Président</td>\n",
              "      <td>1789-09-16</td>\n",
              "      <td>1789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2202</th>\n",
              "      <td>Révolution</td>\n",
              "      <td>Ils veulent en vain persuader aux peuples qne la dissolution de l'empire sera la suite de la Révolution : sans doute on doit s'attendre aux plus grands malheurs si les peuples ne se persuadent pas de la nécessité de rentrer dans l'ordre et dans l'obéissance aux lois ; mais, s'ils se laissaient séduire par les perfides avis qu'on ne cesse de leur donner, ils retomberaient bientôt dans l'esclavage lo plus abject, et sous le fléau d'un despotisme irrité des obstacles qu'il a éprouvés..</td>\n",
              "      <td>APvol9.xml</td>\n",
              "      <td>M. le Président</td>\n",
              "      <td>1789-09-16</td>\n",
              "      <td>1789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2204</th>\n",
              "      <td>Révolution</td>\n",
              "      <td>Ceux qui ont suivi la Révolution ont prévu le point où vous êtes : ils ont prévu que les subsistances manqueraient; qu'on vous montrerait au peuple comme sa seule ressource : ils ont prévu que des situations terribles engageraient à vous demander des mesures violentes, alin d'immoler à la fois, et vous et la liberté..</td>\n",
              "      <td>APvol9.xml</td>\n",
              "      <td>M. Robespierre.</td>\n",
              "      <td>1789-09-16</td>\n",
              "      <td>1789</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1100 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53524e8c-d685-49ff-9e94-8cd0baa6a78c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-53524e8c-d685-49ff-9e94-8cd0baa6a78c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-53524e8c-d685-49ff-9e94-8cd0baa6a78c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d2a65251-637b-409c-8d48-54f1cfbd576b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d2a65251-637b-409c-8d48-54f1cfbd576b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d2a65251-637b-409c-8d48-54f1cfbd576b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_06c77b89-5292-4568-8163-3a74252258d8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_06c77b89-5292-4568-8163-3a74252258d8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         keyword  \\\n",
              "0     Révolution   \n",
              "2     Révolution   \n",
              "4     Révolution   \n",
              "6     Révolution   \n",
              "8     Révolution   \n",
              "...          ...   \n",
              "2196  Révolution   \n",
              "2198  Révolution   \n",
              "2200  Révolution   \n",
              "2202  Révolution   \n",
              "2204  Révolution   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     sentence  \\\n",
              "0     Lorsque nous n'avons pas le texte exact d'un discours dont l'auteur a joué un rôle important sous la Révolution, nous établissons le texte en coordonnant les journaux de l'époque, et pour permettre au lecteur de comparer les différences qui existent entre chacun d'eux, nous donnons en Annexe la version de ces divers journaux..                                                                                                                                                                  \n",
              "2     Comment, Marat aprè|s avoir peinti une partie de la Convention comme suspecte et ennemie de la Révolution, s'écrie : exterminons, sans pitié, tous les conspirateurs ; et l'on dira encore qu'il n'appelle pas le fer sur la tête d'une partie d'entre vous, sur les votants pour l'appel au peuple ou pour la, détention du tyran ou le sursis de son jugement !.                                                                                                                                        \n",
              "4     Examinez ensuite la conduite de ce citoyen, depuis la Révolution..                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
              "6     Attendu enfin que sans m'arrêter au style de Marat, ni à ses idées, je suis forcé de reconnaître en lui un des plus fermes appuis de la Révolution ; que ce citoyen a constamment dénoncé les traîtres et les plus grands conspirateurs, malgré les persécutions les plus fortes, je déclare en mon âme et conscience qu'il n'y a pas lieu à accusation..                                                                                                                                                 \n",
              "8     Provoquons mutuellement la censure publique sur nos actions ; que chacun soit tenu de justifier de ce qu'il a fait pour le peuple avant et depuis la Révolution ; qu'il en soit fait uni tableau soumis à la contradiction des citoyens: alors le peuple distinguera ses vrais amis ; il ne sera plus dupe de ceux qui ne le flattent tant aujourd'hui, que pour mieux l'asservir: je me réserve d'en faire la motion expresse..                                                                          \n",
              "...                                                                                                                                                                                                                                                                                                                                                                                                                                ...                                                                          \n",
              "2196  Vous penserez, Messieurs, que pour l'honneur de la nation française, pour le succès de cette Révolution, l'Assemblée doit prendre des précautions, pour mettre en sûreté les députés du clergé dont vous avez déclaré la personne inviolable et sacrée..                                                                                                                                                                                                                                                  \n",
              "2198  La Révolution qui a été commencée par le courage doit être achevée par la sagesse..                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
              "2200  sur les suites de cette Révolution..                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
              "2202  Ils veulent en vain persuader aux peuples qne la dissolution de l'empire sera la suite de la Révolution : sans doute on doit s'attendre aux plus grands malheurs si les peuples ne se persuadent pas de la nécessité de rentrer dans l'ordre et dans l'obéissance aux lois ; mais, s'ils se laissaient séduire par les perfides avis qu'on ne cesse de leur donner, ils retomberaient bientôt dans l'esclavage lo plus abject, et sous le fléau d'un despotisme irrité des obstacles qu'il a éprouvés..   \n",
              "2204  Ceux qui ont suivi la Révolution ont prévu le point où vous êtes : ils ont prévu que les subsistances manqueraient; qu'on vous montrerait au peuple comme sa seule ressource : ils ont prévu que des situations terribles engageraient à vous demander des mesures violentes, alin d'immoler à la fois, et vous et la liberté..                                                                                                                                                                           \n",
              "\n",
              "         filename              speaker        date  year  \n",
              "0     APvol62.xml  NaN                  1793-04-13  1793  \n",
              "2     APvol62.xml  Delaunay             1793-04-13  1793  \n",
              "4     APvol62.xml  Delaunay             1793-04-13  1793  \n",
              "6     APvol62.xml  Bentabole            1793-04-13  1793  \n",
              "8     APvol62.xml  Bernier              1793-04-13  1793  \n",
              "...           ...      ...                     ...   ...  \n",
              "2196  APvol9.xml   M. l'abbé Grégoire.  1789-09-16  1789  \n",
              "2198  APvol9.xml   M. Bailly.           1789-09-16  1789  \n",
              "2200  APvol9.xml   M. le Président      1789-09-16  1789  \n",
              "2202  APvol9.xml   M. le Président      1789-09-16  1789  \n",
              "2204  APvol9.xml   M. Robespierre.      1789-09-16  1789  \n",
              "\n",
              "[1100 rows x 6 columns]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQlFI2klxALC"
      },
      "source": [
        "## Extract Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNrG0HUDwTOM"
      },
      "outputs": [],
      "source": [
        "class bert_model():\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.config = BertConfig(output_hidden_states=True)\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(name)\n",
        "        self.object = BertModel.from_pretrained(name,\n",
        "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        "                                  )\n",
        "\n",
        "def get_id(key_word, tokenizer):\n",
        "    tokenized_text = tokenizer.tokenize(\"[CLS] \" + key_word + \" [SEP]\")\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "    return indexed_tokens[1:-1]\n",
        "\n",
        "def average_last_4(token_embeddings):\n",
        "    token_vecs_cat = []\n",
        "\n",
        "    for token in token_embeddings:\n",
        "        #stack all into 2d array\n",
        "        cat_vec = torch.stack((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
        "        #take the average across columns\n",
        "        cat_vec = torch.mean(cat_vec, 0)\n",
        "        token_vecs_cat.append(cat_vec)\n",
        "    return token_vecs_cat\n",
        "\n",
        "def extract_word_embeddings_average(model, text, ids):\n",
        "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "    tokenized_text = model.tokenizer.tokenize(marked_text)\n",
        "    indexed_tokens = model.tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "    segments_ids = [1] * len(tokenized_text)\n",
        "    tokens_tensor = torch.tensor([indexed_tokens])\n",
        "    segments_tensors = torch.tensor([segments_ids])\n",
        "\n",
        "    model.object.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.object(tokens_tensor, segments_tensors)\n",
        "        hidden_states = outputs[2]\n",
        "\n",
        "\n",
        "    # WORD EMBEDDING\n",
        "    token_embeddings = torch.stack(hidden_states, dim=0)\n",
        "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "    token_embeddings = token_embeddings.permute(1,0,2)\n",
        "\n",
        "    token_vecs_average_last_4 = average_last_4(token_embeddings)\n",
        "\n",
        "    # Find where keyword is\n",
        "    word_embedding = []\n",
        "    try:\n",
        "        #find the sequence\n",
        "        #take the embedding of the first item in the sequence\n",
        "        index = [(i, i+len(ids)) for i in range(len(indexed_tokens)) if indexed_tokens[i:i+len(ids)] == ids][0][0]\n",
        "        word_embedding = token_vecs_average_last_4[index]\n",
        "\n",
        "    except:\n",
        "        word_embedding = None\n",
        "        #dataset has Albanian instead of just Albania\n",
        "        print(\"Skip sentence\")\n",
        "        return None, None\n",
        "\n",
        "    # SENTENCE EMBEDDING\n",
        "    token_vecs = hidden_states[-2][0]\n",
        "\n",
        "    # Calculate the average of all 22 token vectors.\n",
        "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
        "\n",
        "    return word_embedding, sentence_embedding\n",
        "\n",
        "def run_analysis(model, data, indices, ids):\n",
        "    word_embeddings = []\n",
        "    sentence_embeddings = []\n",
        "    index_numbers = []\n",
        "    for n, row in data.iterrows():\n",
        "        word_embedding, sentence_embedding = extract_word_embeddings_average(model, row[0], ids)\n",
        "        if (word_embedding is not None):\n",
        "            word_embeddings.append(word_embedding)\n",
        "            sentence_embeddings.append(sentence_embedding)\n",
        "            index_numbers.append(indices[n])\n",
        "            #if you found one, then you are good and can move on\n",
        "\n",
        "    return word_embeddings, sentence_embeddings, index_numbers\n",
        "\n",
        "def create_embeddings(filename, data):\n",
        "    append_write = 'w' # make a new file if not\n",
        "    with open(filename, append_write, newline='') as f:\n",
        "        writer = csv.writer(f, delimiter=',')\n",
        "        #change to keyword tag at times\n",
        "        for name, group in data.groupby(['keyword']):\n",
        "            print(name)\n",
        "            #when group is not the same as keyword\n",
        "            name_match = group['keyword'].values[0]\n",
        "            ids = get_id(name_match, model_ml.tokenizer)\n",
        "            word_embeddings, sentence_embeddings, row_numbers = run_analysis(model_ml, pd.DataFrame(group['sentence'].values), group['index'].values, ids)\n",
        "            for word_embedding, sentence_embedding, row_number in zip(word_embeddings, sentence_embeddings, row_numbers):\n",
        "                writer.writerow(word_embedding.tolist() + sentence_embedding.tolist() + [row_number] + [name] + [len(ids)])\n",
        "\n",
        "def create_embeddings_masked(filename, data):\n",
        "    append_write = 'w'\n",
        "    with open(filename, append_write, newline='') as f:\n",
        "        writer = csv.writer(f, delimiter=',')\n",
        "        #change to keyword tag at times\n",
        "        for n, row in data.iterrows():\n",
        "            if (n % 100 == 0):\n",
        "                print(n)\n",
        "            word_embedding, sentence_embedding = extract_word_embeddings_average(model_ml, row['sentence'], ids)\n",
        "            if (word_embedding is not None):\n",
        "                writer.writerow(word_embedding.tolist() + sentence_embedding.tolist() + row.to_list() + [len(ids)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pJRnjL4G3_Jh"
      },
      "outputs": [],
      "source": [
        "keywords = ['Révolution', 'Révolutions', 'révolution', 'contre-révolution', 'contre-révolutions']\n",
        "for word in keywords:\n",
        "  data = pd.read_csv(dest_dir + word + \"_words_with_speaker.csv\")\n",
        "  data['sentence'] = data['sentence'].astype(\"str\")\n",
        "  data = data.reset_index()\n",
        "  data['sentence'] = data['sentence'].str.strip()\n",
        "  data = data[data['year'] != 'year']\n",
        "  data['year'] = data['year'].astype(int)\n",
        "  keywords = [word]\n",
        "\n",
        "  data = data[data['keyword'].isin(keywords)]\n",
        "  data['sentence'] = data['sentence'].apply(lambda x: re.sub(' +', ' ', x))\n",
        "  model_bert_case = bert_model('bert-base-cased')\n",
        "  model_ml = bert_model('bert-base-multilingual-cased')\n",
        "  data = data.reset_index(drop=True)\n",
        "  create_embeddings(dir + word + \"_embeddings_with_speaker.csv\", data)\n",
        "\n",
        "  data['sentence'] = data.apply(lambda x: x['sentence'].replace(x['keyword'], \"[MASK]\"), axis=1)\n",
        "  name_match = '[MASK]' #group['keyword'].values[0]\n",
        "  ids = get_id(name_match, model_ml.tokenizer)\n",
        "\n",
        "  create_embeddings_masked(dir + word + \"_embeddings_with_speaker_masked.csv\", data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGdBbck2-LJY"
      },
      "source": [
        "## Word Confusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9hNbsSpP-ga"
      },
      "source": [
        "### Generate data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQKaSPVeqcBM"
      },
      "outputs": [],
      "source": [
        "# Generate data\n",
        "for word in [\"révolution\", \"Révolution\", \"Révolutions\", \"contre-révolution\", \"contre-révolutions\", \"peuple\", \"personnes\", \"gouvernement\", \"conseil\"]:\n",
        "  embeddings = pd.read_csv(dir + word + \"_embeddings_with_speaker.csv\", header=None)\n",
        "  sentences = pd.read_csv(dir + word + \"_words_with_speaker.csv\")\n",
        "  embeddings = embeddings.set_index(1536).join(sentences.set_index(sentences.index))\n",
        "  embeddings = embeddings.reset_index()\n",
        "  embeddings['vol'] = embeddings['filename'].apply(lambda x: x.split(\".\")[0][5:])\n",
        "  embeddings['vol'] = embeddings['vol'].astype(int)\n",
        "  embeddings.to_csv(dir + word + \"_embeddings_all_year.csv\", mode='w', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b-sGkH-Gmpk"
      },
      "source": [
        "### PCA + Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_boTGbN-iWEJ"
      },
      "outputs": [],
      "source": [
        "contre = 'contre-révolution' # contre-révolution, contre-révolutions\n",
        "revolution = 'révolution' # Révolution, Révolutions, révolution\n",
        "\n",
        "df_contre_revolution = pd.concat([pd.read_csv(dir + contre + \"_embeddings_all_year.csv\"), pd.read_csv(dir + \"contre-révolutions\" + \"_embeddings_all_year.csv\")])\n",
        "df_contre_revolution[\"keyword\"] = contre\n",
        "df_revolution = pd.concat([pd.read_csv(dir + \"Révolution\" + \"_embeddings_all_year.csv\"), pd.read_csv(dir + \"Révolutions\" + \"_embeddings_all_year.csv\"), pd.read_csv(dir + \"révolution\" + \"_embeddings_all_year.csv\")])\n",
        "df_revolution[\"keyword\"] = revolution\n",
        "\n",
        "df_conseil = pd.concat([pd.read_csv(dir + \"gouvernement\" + \"_embeddings_all_year.csv\"), pd.read_csv(dir + \"conseil\" + \"_embeddings_all_year.csv\") ])\n",
        "df_peuple = pd.concat([pd.read_csv(dir + \"personnes\" + \"_embeddings_all_year.csv\"), pd.read_csv(dir + \"peuple\" + \"_embeddings_all_year.csv\")])\n",
        "\n",
        "df_combined = pd.concat([df_contre_revolution, df_revolution], ignore_index=True)\n",
        "\n",
        "# Function to get the probability for a specific class\n",
        "def get_class_probability(classifier, X, target_class):\n",
        "    class_index = list(classifier.classes_).index(target_class)\n",
        "    return classifier.predict_proba(X)[:, class_index]\n",
        "\n",
        "grouped_combined = df_combined.groupby('year')\n",
        "grouped_conseil = df_conseil.groupby('year')\n",
        "grouped_peuple = df_peuple.groupby('year')\n",
        "\n",
        "classifiers = {}\n",
        "\n",
        "# Train classifiers for each year\n",
        "for year in range(1789, 1794):\n",
        "    if year in grouped_conseil.groups and year in grouped_peuple.groups:\n",
        "        data_conseil = grouped_conseil.get_group(year)\n",
        "        data_peuple = grouped_peuple.get_group(year)\n",
        "\n",
        "        X = pd.concat([data_conseil.iloc[:, 0:768], data_peuple.iloc[:, 0:768]]).values\n",
        "        Y = pd.concat([data_conseil['keyword'], data_peuple['keyword']]).values\n",
        "\n",
        "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "        classifier = LogisticRegression(max_iter=500)\n",
        "        classifier.fit(X_train, Y_train)\n",
        "\n",
        "        classifiers[year] = classifier\n",
        "\n",
        "# Iterate through each year from 1789 to 1793.\n",
        "for year in range(1789, 1794):\n",
        "    if year in classifiers and year in grouped_combined.groups:\n",
        "        classifier = classifiers[year]\n",
        "\n",
        "        df_year = grouped_combined.get_group(year)\n",
        "        embeddings = df_year.iloc[:, 0:768].values=\n",
        "\n",
        "        # Predict classes for the embeddings\n",
        "        predictions = classifier.predict(embeddings)\n",
        "\n",
        "        keywords = df_year['keyword'].values\n",
        "\n",
        "        contre_revolution_indices = keywords == contre\n",
        "        contre_embeddings = embeddings[contre_revolution_indices]\n",
        "        scaler_contre = StandardScaler()\n",
        "        contre_embeddings_standardized = scaler_contre.fit_transform(contre_embeddings)\n",
        "\n",
        "        revolution_indices = keywords == revolution\n",
        "        revolution_embeddings = embeddings[revolution_indices]\n",
        "        scaler_revolution = StandardScaler()\n",
        "        revolution_embeddings_standardized = scaler_revolution.fit_transform(revolution_embeddings)\n",
        "\n",
        "        embeddings_standardized = np.zeros_like(embeddings)\n",
        "        embeddings_standardized[contre_revolution_indices] = contre_embeddings_standardized\n",
        "        embeddings_standardized[revolution_indices] = revolution_embeddings_standardized\n",
        "\n",
        "        # Apply PCA on the standardized embeddings\n",
        "        pca = PCA(n_components=2)\n",
        "        pca_result = pca.fit_transform(embeddings_standardized)\n",
        "\n",
        "        mean_contre = pca_result[contre_revolution_indices, 0].mean()\n",
        "        mean_revolution = pca_result[revolution_indices, 0].mean()\n",
        "\n",
        "        ## Plotting\n",
        "        # Determine if the groups are vertically aligned\n",
        "        mean_contre_y = pca_result[contre_revolution_indices, 1].mean()\n",
        "        mean_revolution_y = pca_result[revolution_indices, 1].mean()\n",
        "        if abs(mean_revolution - mean_contre) < abs(mean_revolution_y - mean_contre_y):\n",
        "            # Rotate the points 90 degrees\n",
        "            pca_result = pca_result[:, [1, 0]]\n",
        "        # Flip the PCA results to ensure contre is always at the right\n",
        "        mean_contre = pca_result[contre_revolution_indices, 0].mean()\n",
        "        mean_revolution = pca_result[revolution_indices, 0].mean()\n",
        "        if mean_revolution > mean_contre:\n",
        "            pca_result[:, 0] = -pca_result[:, 0]\n",
        "        pca_result[revolution_indices, 0] -= 30\n",
        "        pca_result[contre_revolution_indices, 0] += 30\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        # Plot points based on the classifier prediction\n",
        "        for i, keyword in enumerate(keywords):\n",
        "            marker = 'o' if keyword == revolution else 'o'\n",
        "            color = 'orange' if predictions[i] == 'personnes' or predictions[i] == 'peuple' else 'blue'\n",
        "            plt.scatter(pca_result[i, 0], pca_result[i, 1], color=color, marker=marker, alpha=0.5)\n",
        "        # Set the same x and y axis limits for consistency across plots\n",
        "        plt.xlim([-60, 60])\n",
        "        plt.ylim([-30, 30])\n",
        "        plt.xticks(np.arange(-60, 61, 20))\n",
        "        plt.yticks(np.arange(-30, 31, 10))\n",
        "        plt.tick_params(axis='both', which='major', labelsize=14)  # Set tick font size to 14\n",
        "        plt.xlabel('PCA Component 1')\n",
        "        plt.ylabel('PCA Component 2')\n",
        "        plt.title(f'PCA of Embeddings for Year {year}')\n",
        "        # Legend\n",
        "        handles = [\n",
        "            plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='orange', markersize=10, label=\"people\"),\n",
        "            plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='blue', markersize=10, label=\"government\"),\n",
        "        ]\n",
        "        plt.legend(handles=handles)\n",
        "        plt.grid(True)\n",
        "        plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "xhb3dlX2w8v1",
        "715GXH42R54H",
        "fLe1IOuRd3BW",
        "4k1HXctJR-Z2",
        "cRFGCaUh0mQd",
        "LQlFI2klxALC"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}